{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "import nltk\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"autonom.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup(text):\n",
    "    text = BeautifulSoup(text, \"html5lib\").get_text()\n",
    "    return text\n",
    "df['text'] = df['text'].apply(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of words in patent abstract that do not inform.\n",
    "stop_list = [\n",
    "'claims','claim', 'method', 'provide', 'provided', \\\n",
    "'device', 'devices','apparatus','system', 'systems', \\\n",
    "'apparatuses', 'embodiments', 'embodiment','examples', \\\n",
    "'example','inventions', 'invention', 'present', \\\n",
    "'includes', 'include', 'including','description', \\\n",
    "'user', 'body', 'power', 'person', 'persons', \\\n",
    "'comprising', 'comprise', 'comprises', 'configured', \\\n",
    "'configure','for example', 'discloses', 'disclose', \\\n",
    "'method', 'said', 'abstract', 'abstracts', 'disclosed', 'herein', \\\n",
    "'autonomous', 'vehicle', 'self-driving', 'sensor'\n",
    "]\n",
    "\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "#larger list containing all custom stop words as well as from NLP libraries\n",
    "stop = set(list(stop_list) + list(ENGLISH_STOP_WORDS) \\\n",
    "           + stopwords.words('english') + punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeText(text):\n",
    "    #clean text using regex\n",
    "    separators = [\"\\xa0\\xa0\\xa0\\xa0\", \"\\r\", \"\\n\",\\\n",
    "                  \"\\t\", \"n't\", \"'m\", \"'ll\", '[^a-z ]'\\\n",
    "                 '[\\s]+',r'[^\\w]','^\\d+\\s|\\s\\d+\\s|\\s\\d+$']\n",
    "    for i in separators:\n",
    "        text = re.sub(i, \" \", text.lower())\n",
    "    #use Spacy to parse text    \n",
    "    tokens = parser(text)\n",
    "    tokens = [tok.lemma_.strip() for tok in tokens]\n",
    "\n",
    "    #apply stoplist\n",
    "    return [tok for tok in tokens if len(tok) != 1 and tok not in stop]\n",
    "\n",
    "def text_processing(corp):\n",
    "    corp = tokenizeText(corp)\n",
    "    return ' '.join(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priority date\n",
       "2015-12-08    current state identify path curvature limit de...\n",
       "2013-02-27    radar operate various mode various configurati...\n",
       "2014-06-05    path plan generation automate lane center lane...\n",
       "2013-03-05    adaptable flight water travel wing stabilizer ...\n",
       "2015-06-08    various manner change travel lane target gap p...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(df, open(\"autonom_lemmatized.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
